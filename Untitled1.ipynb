{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53becd7a-0e9b-430d-ad2d-268df8056197",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID: Dataset\n",
      "No. of Features: 8\n",
      "Number of Instances: 768\n",
      "Missing Values: 0\n",
      "Outliers: 4221\n",
      "Feature Correlations:\n",
      "Outcome                     1.000000\n",
      "Glucose                     0.466581\n",
      "BMI                         0.292695\n",
      "Age                         0.238356\n",
      "Pregnancies                 0.221898\n",
      "DiabetesPedigreeFunction    0.173844\n",
      "Insulin                     0.130548\n",
      "SkinThickness               0.074752\n",
      "BloodPressure               0.065068\n",
      "Name: Outcome, dtype: float64\n",
      "Data Type: [dtype('int64') dtype('float64')]\n",
      "\n",
      "Accuracy Scores:\n",
      "Decision Tree : 79.22%\n",
      "Random Forest : 74.03%\n",
      "Logistic Regression : 74.68%\n",
      "Support Vector Machine : 76.62%\n",
      "Naive Bayes : 76.62%\n",
      "K-Nearest Neighbors : 64.94%\n",
      "\n",
      "Best Algorithm: Decision Tree\n",
      "\n",
      "Diabetes Dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI   \n",
      "0            6      148             72             35        0  33.6  \\\n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset from a CSV file\n",
    "diabetes_data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "dataset_id = 'Dataset'\n",
    "num_features = len(diabetes_data.columns) - 1  # Exclude the target column\n",
    "num_instances = len(diabetes_data)\n",
    "missing_values = diabetes_data.isnull().sum().sum()\n",
    "outliers = (np.abs(diabetes_data.drop('Outcome', axis=1) - diabetes_data.drop('Outcome', axis=1).mean()) > 3).sum().sum()\n",
    "feature_correlations = diabetes_data.corr()['Outcome'].abs().sort_values(ascending=False)\n",
    "data_type = diabetes_data.dtypes.unique()\n",
    "\n",
    "print(\"Dataset ID:\", dataset_id)\n",
    "print(\"No. of Features:\", num_features)\n",
    "print(\"Number of Instances:\", num_instances)\n",
    "print(\"Missing Values:\", missing_values)\n",
    "print(\"Outliers:\", outliers)\n",
    "print(\"Feature Correlations:\")\n",
    "print(feature_correlations)\n",
    "print(\"Data Type:\", data_type)\n",
    "\n",
    "# Drop instances with missing values\n",
    "diabetes_data.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = diabetes_data.drop('Outcome', axis=1)\n",
    "y = diabetes_data['Outcome']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=5, min_samples_split=2)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt) * 100\n",
    "\n",
    "# Train and evaluate the random forest classifier\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf) * 100\n",
    "\n",
    "# Train and evaluate the logistic regression classifier\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr) * 100\n",
    "\n",
    "# Train and evaluate the support vector machine classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm) * 100\n",
    "\n",
    "# Train and evaluate the naive bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb) * 100\n",
    "\n",
    "# Train and evaluate the k-nearest neighbors classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)  # Set n_neighbors to a lower value\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn) * 100\n",
    "\n",
    "# Compare the accuracies of different algorithms\n",
    "accuracies = {\n",
    "    'Decision Tree': accuracy_dt,\n",
    "    'Random Forest': accuracy_rf,\n",
    "    'Logistic Regression': accuracy_lr,\n",
    "    'Support Vector Machine': accuracy_svm,\n",
    "    'Naive Bayes': accuracy_nb,\n",
    "    'K-Nearest Neighbors': accuracy_knn\n",
    "}\n",
    "\n",
    "best_algorithm = max(accuracies, key=accuracies.get)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nAccuracy Scores:\")\n",
    "for algorithm, accuracy in accuracies.items():\n",
    "    print(algorithm, \":\", \"{:.2f}%\".format(accuracy))\n",
    "\n",
    "print(\"\\nBest Algorithm:\", best_algorithm)\n",
    "\n",
    "# Display the head of the diabetes dataset\n",
    "print(\"\\nDiabetes Dataset:\")\n",
    "print(diabetes_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8f8a19-2ae4-4401-9ceb-323f83369ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results:\n",
      "          Method  Training MSE  Training R2  Test MSE  Test R2\n",
      "0  Decision Tree      0.000000      1.00000  0.033856      NaN\n",
      "1  Random Forest      0.119277      0.81539  0.060627      NaN\n",
      "\n",
      "Dataset Information:\n",
      "\n",
      "Dataset ID: Dataset\n",
      "No. of Features: 9\n",
      "Number of Instances: 5\n",
      "Missing Values: 0\n",
      "Outliers: 25\n",
      "Feature Correlations:\n",
      "Outcome                     1.000000\n",
      "Glucose                     0.911585\n",
      "Age                         0.646147\n",
      "DiabetesPedigreeFunction    0.606669\n",
      "Pregnancies                 0.563547\n",
      "BMI                         0.422899\n",
      "BloodPressure               0.322832\n",
      "SkinThickness               0.100599\n",
      "Insulin                     0.064545\n",
      "Unnamed: 0                  0.000000\n",
      "Name: Outcome, dtype: float64\n",
      "Data Type: [dtype('int64') dtype('float64')]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = pd.read_csv(\"diabetes_dataset.csv\")\n",
    "\n",
    "# Data Separation into X and Y\n",
    "y = diabetes[\"DiabetesPedigreeFunction\"]\n",
    "x = diabetes.drop('DiabetesPedigreeFunction', axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Building and Training - Decision Tree\n",
    "decision_tree_model = DecisionTreeRegressor()\n",
    "decision_tree_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate Decision Tree model performance\n",
    "y_model_train_pred = decision_tree_model.predict(X_train)\n",
    "y_model_test_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "model_train_mse = mean_squared_error(Y_train, y_model_train_pred)\n",
    "model_train_r2 = r2_score(Y_train, y_model_train_pred)\n",
    "model_test_mse = mean_squared_error(Y_test, y_model_test_pred)\n",
    "model_test_r2 = r2_score(Y_test, y_model_test_pred)\n",
    "\n",
    "# Model Building and Training - Random Forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=2, random_state=100)\n",
    "random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate Random Forest model performance\n",
    "y_rf_train_pred = random_forest_model.predict(X_train)\n",
    "y_rf_test_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "rf_train_mse = mean_squared_error(Y_train, y_rf_train_pred)\n",
    "rf_train_r2 = r2_score(Y_train, y_rf_train_pred)\n",
    "rf_test_mse = mean_squared_error(Y_test, y_rf_test_pred)\n",
    "rf_test_r2 = r2_score(Y_test, y_rf_test_pred)\n",
    "\n",
    "# Create a DataFrame to store model results\n",
    "model_results = pd.DataFrame(\n",
    "    [\n",
    "        ['Decision Tree', model_train_mse, model_train_r2, model_test_mse, model_test_r2],\n",
    "        ['Random Forest', rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]\n",
    "    ],\n",
    "    columns=['Method', 'Training MSE', 'Training R2', 'Test MSE', 'Test R2']\n",
    ")\n",
    "\n",
    "# Additional models and accuracy scores\n",
    "# Add code to train and evaluate other models (e.g., Logistic Regression, SVM, Naive Bayes, KNN) and store their results in the DataFrame\n",
    "\n",
    "# Dataset information\n",
    "dataset_info = \"\"\"\n",
    "Dataset ID: Dataset\n",
    "No. of Features: 9\n",
    "Number of Instances: {}\n",
    "Missing Values: {}\n",
    "Outliers: {}\n",
    "Feature Correlations:\n",
    "Outcome                     1.000000\n",
    "Glucose                     0.911585\n",
    "Age                         0.646147\n",
    "DiabetesPedigreeFunction    0.606669\n",
    "Pregnancies                 0.563547\n",
    "BMI                         0.422899\n",
    "BloodPressure               0.322832\n",
    "SkinThickness               0.100599\n",
    "Insulin                     0.064545\n",
    "Unnamed: 0                  0.000000\n",
    "Name: Outcome, dtype: float64\n",
    "Data Type: [dtype('int64') dtype('float64')]\n",
    "\"\"\".format(len(diabetes), diabetes.isnull().sum().sum(), 25)\n",
    "\n",
    "# Print the model results and dataset information\n",
    "print(\"Model Results:\")\n",
    "print(model_results)\n",
    "print(\"\\nDataset Information:\")\n",
    "print(dataset_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db48c1a6-3ae4-4600-9852-0e334482d221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.167, 0.627, 0.672, 2.288]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Iterate over the models\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py:267\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    266\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_refit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py:427\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _refit:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[43m_check_partial_fit_first_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:420\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[0;34m(clf, classes)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    414\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`classes=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m` is not the same as on last call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto partial_fit, was: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (classes, clf\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m    416\u001b[0m             )\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;66;03m# This is the first call to partial_fit\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m         clf\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# nothing to do\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:107\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    105\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([0.167, 0.627, 0.672, 2.288]),)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Read the dataset\n",
    "diabetes = pd.read_csv(\"diabetes_dataset.csv\")\n",
    "\n",
    "# Data Separation as X and Y\n",
    "y = diabetes[\"DiabetesPedigreeFunction\"]\n",
    "x = diabetes.drop('DiabetesPedigreeFunction', axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=2, random_state=100),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over the models\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    train_mse = mean_squared_error(Y_train, y_train_pred)\n",
    "    train_r2 = r2_score(Y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(Y_test, y_test_pred)\n",
    "    test_r2 = r2_score(Y_test, y_test_pred)\n",
    "\n",
    "    # Store the results\n",
    "    results.append([model_name, train_mse, train_r2, test_mse, test_r2])\n",
    "\n",
    "# Create a dataframe to display the results\n",
    "columns = ['Method', 'Training MSE', 'Training R2', 'Test MSE', 'Test R2']\n",
    "model_results = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Find the model with the highest test R2 score\n",
    "best_model = model_results.loc[model_results['Test R2'].idxmax()]\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(\"Best Model:\")\n",
    "print(best_model['Method'])\n",
    "print(\"Test R2:\", best_model['Test R2'] * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05a3e38-4069-4cc4-8fa3-0c7894ce5069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate performance metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_regression.py:236\u001b[0m, in \u001b[0;36mKNeighborsRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the target for the provided data.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Target values.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:810\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    808\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    815\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    816\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 5"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Read the dataset\n",
    "diabetes = pd.read_csv(\"diabetes_dataset.csv\")\n",
    "\n",
    "# Data Separation as X and Y\n",
    "y = diabetes[\"DiabetesPedigreeFunction\"]\n",
    "x = diabetes.drop('DiabetesPedigreeFunction', axis=1)\n",
    "\n",
    "# Label encoding for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(max_depth=2, random_state=100),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over the models\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    train_mse = mean_squared_error(Y_train, y_train_pred)\n",
    "    train_r2 = r2_score(Y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(Y_test, y_test_pred)\n",
    "    test_r2 = r2_score(Y_test, y_test_pred)\n",
    "\n",
    "    # Store the results\n",
    "    results.append([model_name, train_mse, train_r2, test_mse, test_r2])\n",
    "\n",
    "# Create a dataframe to display the results\n",
    "columns = ['Method', 'Training MSE', 'Training R2', 'Test MSE', 'Test R2']\n",
    "model_results = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Find the model with the highest test R2 score\n",
    "best_model = model_results.loc[model_results['Test R2'].idxmax()]\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(\"Best Model:\")\n",
    "print(best_model['Method'])\n",
    "print(\"Test R2:\", best_model['Test R2'] * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0ef64-e3bb-44fe-bb61-76a60b4e458d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ce962-95e9-4669-9056-f7e7b85c66de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
